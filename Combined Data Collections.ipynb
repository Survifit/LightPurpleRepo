{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UofMN Visualization and Analytics Bootcamp \n",
    "## Group 3 - Project 1 Data Collection Notebook 04/13/2019\n",
    "#### James Dietz, Stephanie Hartje, Chris Howard, Emily Hudson, Marie Wothe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All imported packages\n",
    "* Note - all outputs have been commented out to avoid over-writing live project data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from config import omdb_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collect data from bechdeltest.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chris Howard\n",
    "# Create base URL and response script for bechdeltest.com\n",
    "# url = \"http://bechdeltest.com/api/v1/getAllMovies\"\n",
    "\n",
    "# response = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '8040',\n",
      " 'imdbid': '0392728',\n",
      " 'rating': '0',\n",
      " 'title': 'Roundhay Garden Scene',\n",
      " 'year': '1888'}\n"
     ]
    }
   ],
   "source": [
    "# Chris Howard\n",
    "# Check initial frame of response to confirm successful data collection.\n",
    "#pprint(response[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chris Howard\n",
    "# Create dataframe from the response\n",
    "bechdel_df = pd.DataFrame(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chris Howard\n",
    "# Look at header of response and save to .csv\n",
    "bechdel_df.head()\n",
    "#bechdel_df.to_csv(\"Data/bechdel_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chris Howard\n",
    "# Data set too large to collect from OMDB API in one download, split into 9 sub-1000 entry sets\n",
    "# Perform the split and test the initial save\n",
    "split_df = np.array_split(bechdel_df, 9)\n",
    "tue_1 = split_df[0]\n",
    "#tue_1['imdbid'].to_csv('Data/james_tues.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chris Howard\n",
    "# Save remaining sections of data split into .csv files for each team member to use for OMDB downloads\n",
    "tue_2 = split_df[1]\n",
    "#tue_2['imdbid'].to_csv('Data/emily_tues.csv')\n",
    "tue_3 = split_df[2]\n",
    "#tue_3['imdbid'].to_csv('Data/stephanie_tues.csv')\n",
    "tue_4 = split_df[3]\n",
    "#tue_4['imdbid'].to_csv('Data/marie_tues.csv')\n",
    "tue_5 = split_df[4]\n",
    "#tue_5['imdbid'].to_csv('Data/chris_tues.csv')\n",
    "wed_1 = split_df[5]\n",
    "#wed_1['imdbid'].to_csv('Data/chris_wed.csv')\n",
    "wed_2 = split_df[6]\n",
    "#wed_2['imdbid'].to_csv('Data/marie_wed.csv')\n",
    "wed_3 = split_df[7]\n",
    "#wed_3['imdbid'].to_csv('Data/stephanie_wed.csv')\n",
    "wed_4 = split_df[8]\n",
    "#wed_4['imdbid'].to_csv('Data/emily_wed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imdbid</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8071</th>\n",
       "      <td>8617</td>\n",
       "      <td>5316540</td>\n",
       "      <td>3</td>\n",
       "      <td>Close</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8072</th>\n",
       "      <td>8642</td>\n",
       "      <td>0437086</td>\n",
       "      <td>3</td>\n",
       "      <td>Alita: Battle Angel</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8073</th>\n",
       "      <td>8655</td>\n",
       "      <td>7458762</td>\n",
       "      <td>0</td>\n",
       "      <td>Le chant du loup</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074</th>\n",
       "      <td>8659</td>\n",
       "      <td>2452244</td>\n",
       "      <td>1</td>\n",
       "      <td>Isn&amp;#39;t It Romantic</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8075</th>\n",
       "      <td>8668</td>\n",
       "      <td>4154664</td>\n",
       "      <td>3</td>\n",
       "      <td>Captain Marvel</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   imdbid rating                  title  year\n",
       "8071  8617  5316540      3                  Close  2019\n",
       "8072  8642  0437086      3    Alita: Battle Angel  2019\n",
       "8073  8655  7458762      0       Le chant du loup  2019\n",
       "8074  8659  2452244      1  Isn&#39;t It Romantic  2019\n",
       "8075  8668  4154664      3         Captain Marvel  2019"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chris Howard\n",
    "# Confirm that the end of the final split is the same as the end of the original response dataframe\n",
    "wed_4.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data from OMDB API\n",
    "* Note - this is just an example, each team member had a similar notebook to run on consecutive days to collect all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chris Howard\n",
    "# OMDB URL, confirm format with print statement\n",
    "base_url = f'http://www.omdbapi.com/?apikey={omdb_key}&i=tt'\n",
    "#print(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chris Howard\n",
    "# This section to be run on the first day to collect first segment of OMDB data associated with Bechdel set\n",
    "# Run on Tuesday\n",
    "tues_data = pd.read_csv('Data/chris_tues.csv', header=None)\n",
    "\n",
    "omdb_ids = tues_data.iloc[:,1]\n",
    "\n",
    "\n",
    "movie_data = []\n",
    "\n",
    "for omdb_id in omdb_ids:\n",
    "    # convert ID field to string\n",
    "    omdb_id = str(omdb_id)\n",
    "    \n",
    "    # replace leading zeros for IMDB id numbers lost in .csv save\n",
    "    while len(omdb_id) < 7:\n",
    "        omdb_id = '0' + omdb_id\n",
    "    \n",
    "    # get response from OMDB and store in movie_data list\n",
    "    url = base_url + omdb_id\n",
    "    response = requests.get(url).json()\n",
    "    movie_data.append(response)\n",
    "\n",
    "# Create datafram from movie responses\n",
    "movies = pd.DataFrame(movie_data)\n",
    "\n",
    "# Save to csv file\n",
    "#movies.to_csv('Data/chris_tues_moviedata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chris Howard\n",
    "# This section to be run on the second day to collect the second segment of OMDB data associated with Bechdel set\n",
    "# Run on Wednesday\n",
    "tues_data = pd.read_csv('Data/chris_wed.csv', header=None)\n",
    "\n",
    "omdb_ids = tues_data.iloc[:,1]\n",
    "\n",
    "\n",
    "movie_data = []\n",
    "\n",
    "for omdb_id in omdb_ids:\n",
    "    # convert ID field to string\n",
    "    omdb_id = str(omdb_id)\n",
    "    \n",
    "    # replace leading zeros for IMDB id numbers lost in .csv save\n",
    "    while len(omdb_id) < 7:\n",
    "        omdb_id = '0' + omdb_id\n",
    "    \n",
    "    # get response from OMDB and store in movie_data list\n",
    "    url = base_url + omdb_id\n",
    "    response = requests.get(url).json()\n",
    "    movie_data.append(response)\n",
    "\n",
    "# Create datafram from movie responses\n",
    "movies = pd.DataFrame(movie_data)\n",
    "\n",
    "# Save to csv file\n",
    "#movies.to_csv('Data/chris_wed_moviedata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Scraping for Revenue Data based on script from zacharyang@GitHub\n",
    "* This data was collected, but ultimately not used for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chris Howard\n",
    "# Different import syntax, completed in separate notebook.\n",
    "# Credit to zacharyang@GitHub for scraping script. \n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as rq\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def convdollar(x):\n",
    "    \"\"\"\n",
    "    Just a parsing function converting 2.5k to 2500, 1mil to 1000000\n",
    "    \"\"\"\n",
    "    if 'k' in x:\n",
    "        return float(x.replace('k',''))*1000\n",
    "    else:\n",
    "        return float(x)*1000000\n",
    "\n",
    "def scrape():\n",
    "    \"\"\"\n",
    "    Gets all box office data from 1989 to 2018 from boxofficemojo.com\n",
    "    \"\"\"\n",
    "    years=[str(a) for a in range(1980,2019)]\n",
    "    df_list=[]\n",
    "    for year in years:\n",
    "        r=rq.get('https://www.boxofficemojo.com/yearly/chart/?view2=worldwide&yr=%s&p=.htm' % year)\n",
    "        print('Box Office data for %s scraped' % year)\n",
    "        p=BeautifulSoup(r.text,'html.parser')\n",
    "        ### Look for the table ### \n",
    "        b=p.find_all('table')\n",
    "        ### Usually the fourth table object on page ### \n",
    "        tb=b[3].find_all('td')\n",
    "        data=[]\n",
    "        for i in tb:\n",
    "            if i.find('a')!=None:\n",
    "                data.append(i.find('a').contents[0])\n",
    "            elif i.find('font')!=None:\n",
    "                 data.append(i.find('font').contents[0])\n",
    "            elif i.find('b')!=None:\n",
    "                data.append(i.find('b').contents[0])\n",
    "        ### Still a <b> tag left for <font> tags ## \n",
    "        data=[a.contents[0] if type(a)!=bs4.element.NavigableString else a for a in data]\n",
    "        ### Strip special characters ### \n",
    "        data=[re.sub('[^A-Za-z0-9-. ]+', '', a) for a in data]\n",
    "        ### Fill NaNs ### \n",
    "        data=[np.nan if a =='na' else a for a in data]\n",
    "        columns=['bo_year_rank','title','studio','worldwide-gross','domestic-gross','domestic-pct','overseas-gross','overseas-pct']\n",
    "        to_df=data[6:]\n",
    "        if len(to_df)%len(columns) != 0:\n",
    "            print('Possible table misalignment in table for year %s' % year)\n",
    "            break \n",
    "        nrow=int(len(to_df)/len(columns))\n",
    "        df=pd.DataFrame(np.array(to_df).reshape(nrow,8),columns=columns)\n",
    "        df[['worldwide-gross','domestic-gross','overseas-gross']]=df[['worldwide-gross','domestic-gross','overseas-gross']].applymap(lambda x:convdollar(x))\n",
    "        df['bo_year']=int(year)\n",
    "        df_list.append(df)\n",
    "\n",
    "    main=pd.concat(df_list)\n",
    "\n",
    "    main.to_csv('./Data/annual_mojo1980.csv')\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\": \n",
    "\n",
    "    scrape()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull all OMDB data files together into a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chris Howard\n",
    "# Read each file into a dataframe and append together\n",
    "data1 = pd.read_csv('chris_tues_moviedata.csv')\n",
    "data2 = pd.read_csv('chris_wed_moviedata.csv')\n",
    "data3 = pd.read_csv('emily_tues_moviedata.csv')\n",
    "data4 = pd.read_csv('emily_wed_moviedata.csv')\n",
    "data5 = pd.read_csv('james_tues_moviedata.csv')\n",
    "data6 = pd.read_csv('marie_tues_moviedata.csv')\n",
    "data7 = pd.read_csv('marie_wed_moviedata.csv')\n",
    "data8 = pd.read_csv('stephanie_tues_moviedata.csv')\n",
    "data9 = pd.read_csv('stephanie_wed_moviedata.csv')\n",
    "data1 = data1.append([data2, data3, data4, data5, data6, data7, data8, data9])\n",
    "\n",
    "#data1.to_csv('full_moviedata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge OMDB and Bechdeltest.com data into a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emily Hudson\n",
    "# Read in OMDB and bechdeltest.com .csv files\n",
    "df = pd.read_csv(\"full_moviedata.csv\")\n",
    "df_b = pd.read_csv(\"bechdel_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emily Hudson\n",
    "# Change imdbID column to type string, confirm column names for OMDB data\n",
    "df[\"imdbID\"]=df[\"imdbID\"].astype(str)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emily Hudson\n",
    "# Confirm column names for bechdeltest.com data\n",
    "df_b.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emily Hudson\n",
    "# Change bechdelltest.com imdbID column to type string, then add back zeros stripped by .csv\n",
    "# then append 'tt' for proper IMDB id format and save back to dataframe\n",
    "df_b[\"imdbid\"]=df_b[\"imdbid\"].astype(str)\n",
    "newID = []\n",
    "\n",
    "for id in df_b[\"imdbid\"]:\n",
    "    while len(id) < 7:\n",
    "        id = '0' + str(id) \n",
    "    id = 'tt' + str(id)\n",
    "    newID.append(id)\n",
    "df_b[\"imdbID\"] = newID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emily Hudson\n",
    "# Merge dataframes together and export to full .csv\n",
    "full_b = pd.merge(df, df_b, on=\"imdbID\")\n",
    "#full_b.to_csv(\"primary_merge.csv\", index=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stephanie Hartje\n",
    "# Load and inspect merged datafile\n",
    "df = pd.read_csv(\"primary_merge.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stephanie Hartje\n",
    "# Remove unnamed data columns with no usable information\n",
    "del df['Unnamed: 0_x']\n",
    "del df['Unnamed: 0_y']\n",
    "del df['Unnamed: 0.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stephanie Hartje \n",
    "# Remove columns not needed for analysis, or that indicate the subject is not a movie (tv series etc).\n",
    "#Note from Steph - del df_movie['year'] looks like it's included twice and it's generating an error message.\n",
    "#For now I commented out the duplicate.  If others agree it's a duplicate we can delete.\n",
    "del df_movie['Episode']\n",
    "del df_movie['Error']\n",
    "del df_movie['Response']\n",
    "del df_movie['Season']\n",
    "del df_movie['Type']\n",
    "del df_movie['seriesID']\n",
    "del df_movie['totalSeasons']\n",
    "del df_movie['title']\n",
    "del df_movie['year']\n",
    "del df_movie['imdbid']\n",
    "del df_movie['id']\n",
    "#del df_movie['year']\n",
    "\n",
    "df_movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stephanie Hartje\n",
    "#SHartje's Edits start here\n",
    "#Fixing characters that were messed up when data was pulled, merged, etc.\n",
    "\n",
    "#Create a list of the column headings\n",
    "Titles = list(df_movie)\n",
    "\n",
    "#Cycle through the list of column headings and convert each column from iso-8859-1 to utf-8\n",
    "for Title in Titles:\n",
    "    try:\n",
    "        df_movie[Title] = df_movie[Title].str.decode('iso-8859-1').str.encode('utf-8')\n",
    "    except:\n",
    "        df_movie[Title] = df_movie[Title]\n",
    "\n",
    "#display the dataframe to check \n",
    "df_movie.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stephanie Hartje\n",
    "# Export clean data to .csv for group to use in analyses\n",
    "#df_movie.to_csv(\"clean_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
